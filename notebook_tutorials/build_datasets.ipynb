{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CollabLLM Dataset Construction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two types of datasets in CollabLLM:\n",
    "- SingTurnDataset: Any single-turn tasks can be defined as a SingTurnDataset.\n",
    "- MultiTurnDataset: Any multiturn conversation can be stored as MultiTurnDataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single-turn dataset\n",
    "\n",
    "Demonstrates:\n",
    "1. Creating a list of single-turn chat entries.\n",
    "2. Wrapping it with SingTurnDataset.\n",
    "3. Converting to a HuggingFace DatasetDict.\n",
    "4. Inspecting splits and sample entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dfs/scratch0/shirwu/anaconda3/envs/collabllm-delta/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-06-14 16:50:38,844 [INFO] collabllm: CollabLLM logging enabled.\n",
      "2025-06-14 16:50:39,994 [INFO] httpx: HTTP Request: GET https://raw.githubusercontent.com/BerriAI/litellm/main/model_prices_and_context_window.json \"HTTP/1.1 200 OK\"\n",
      "2025-06-14 16:50:41,920 [INFO] collabllm: Disable LiteLLM cache and logging by default. \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"/dfs/project/kgrlm/github/collabllm\") \n",
    "from pprint import pprint\n",
    "from datasets import DatasetDict\n",
    "from collabllm.datasets import SingleTurnDataset\n",
    "\n",
    "# ------------------------------------------------------ #\n",
    "# 1) Prepare some toy single-turn data                   #\n",
    "# ------------------------------------------------------ #\n",
    "toy_data = [\n",
    "    {\n",
    "        \"prompt\": \"What is the capital of France?\",\n",
    "        \"completion\": \"Paris.\",\n",
    "        \"difficulty\": \"easy\",\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"Compute 15 * 7.\",\n",
    "        \"completion\": \"105.\",\n",
    "        \"difficulty\": \"easy\",\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"Explain the theory of relativity in brief.\",\n",
    "        \"completion\": \"It’s a theory by Einstein explaining how space and time are linked and how massive objects curve spacetime. In short, E=mc².\",\n",
    "        \"difficulty\": \"hard\",\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"Who wrote 'Pride and Prejudice'?\",\n",
    "        \"completion\": \"Jane Austen.\",\n",
    "        \"difficulty\": \"medium\",\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"Translate 'Hello' to Spanish.\",\n",
    "        \"completion\": \"Hola.\",\n",
    "        \"difficulty\": \"easy\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------ #\n",
    "# 2) Initialize SingleTurnDataset                          #\n",
    "# ------------------------------------------------------ #\n",
    "dataset = SingleTurnDataset(toy_data, eval_ratio=0.2, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset splits: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['single_turn_prompt', 'single_turn_completion', 'single_turn_metadata'],\n",
      "        num_rows: 4\n",
      "    })\n",
      "    eval: Dataset({\n",
      "        features: ['single_turn_prompt', 'single_turn_completion', 'single_turn_metadata'],\n",
      "        num_rows: 1\n",
      "    })\n",
      "})\n",
      "Split info: {'train': 4, 'eval': 1}\n",
      "\n",
      "--- TRAIN split ---\n",
      "{'single_turn_completion': '105.',\n",
      " 'single_turn_metadata': {'difficulty': 'easy'},\n",
      " 'single_turn_prompt': 'Compute 15 * 7.'}\n",
      "\n",
      "--- EVAL split ---\n",
      "{'single_turn_completion': 'Paris.',\n",
      " 'single_turn_metadata': {'difficulty': 'easy'},\n",
      " 'single_turn_prompt': 'What is the capital of France?'}\n",
      "\n",
      "First entry via __getitem__:\n",
      "{'prompt': 'What is the capital of France?', 'completion': 'Paris.', 'difficulty': 'easy'}\n",
      "\n",
      "Total entries: 5\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------ #\n",
    "# 3) Convert to HuggingFace DatasetDict                  #\n",
    "# ------------------------------------------------------ #\n",
    "hf_datasets: DatasetDict = dataset.to_hf_dataset()\n",
    "print(\"Dataset splits:\", hf_datasets)\n",
    "\n",
    "# ------------------------------------------------------ #\n",
    "# 4) Inspect split sizes                                #\n",
    "# ------------------------------------------------------ #\n",
    "splits_info = dataset.get_splits_info()\n",
    "print(\"Split info:\", splits_info)\n",
    "\n",
    "# ------------------------------------------------------ #\n",
    "# 5) Peek at one example from each split                 #\n",
    "# ------------------------------------------------------ #\n",
    "for split_name, split_ds in hf_datasets.items():\n",
    "    print(f\"\\n--- {split_name.upper()} split ---\")\n",
    "    # Each row has: single_turn_prompt, single_turn_completion, metadata\n",
    "    row0 = split_ds[0]\n",
    "    pprint(row0)\n",
    "\n",
    "# ------------------------------------------------------ #\n",
    "# 6) Accessing entries via __getitem__                   #\n",
    "# ------------------------------------------------------ #\n",
    "print(\"\\nFirst entry via __getitem__:\")\n",
    "print(dataset[0])\n",
    "\n",
    "print(\"\\nTotal entries:\", len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiturn dataset\n",
    "\n",
    "There are two ways to create a multiturn dataset:\n",
    "- Provide a list of data entries (by separated rows or nested dictionary).\n",
    "- Specifify a huggingface dataset repo name ([example format](https://huggingface.co/datasets/collabllm/collabllm-multiturn-math-hard)) or a local directory containing a huggingface dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1.1: Create a multiturn dataset from a list of data entries (separated rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-14 16:51:32,338 [INFO] collabllm.datasets.multiturn: Converted 3 dialogues (filter: None ≥ 0.0); retention ratio: 1.00\n",
      "2025-06-14 16:51:32,352 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=3 (turn_id=1) due to score=0.500 < 0.600\n",
      "2025-06-14 16:51:32,353 [INFO] collabllm.datasets.multiturn: Converted 2 dialogues (filter: score ≥ 0.6); retention ratio: 0.67\n",
      "2025-06-14 16:51:32,366 [INFO] collabllm.datasets.multiturn: Converted 2 pairs (minimum_gap=0.2, ratio=0.33)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SFT:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['messages'],\n",
      "        num_rows: 3\n",
      "    })\n",
      "    eval: Dataset({\n",
      "        features: ['messages'],\n",
      "        num_rows: 0\n",
      "    })\n",
      "})\n",
      "{'messages': [{'content': 'Hi – tell me a joke.', 'role': 'user'},\n",
      "              {'content': 'Why did the chicken cross the road? To get to the '\n",
      "                          'other side!',\n",
      "               'role': 'assistant'},\n",
      "              {'content': 'And another one?', 'role': 'user'},\n",
      "              {'content': 'What do you call a bear with no teeth? A gummy '\n",
      "                          'bear!',\n",
      "               'role': 'assistant'}]}\n",
      "\n",
      "SFT (lower bound=0.6):\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['messages'],\n",
      "        num_rows: 2\n",
      "    })\n",
      "    eval: Dataset({\n",
      "        features: ['messages'],\n",
      "        num_rows: 0\n",
      "    })\n",
      "})\n",
      "{'messages': [{'content': 'Hi – tell me a joke.', 'role': 'user'},\n",
      "              {'content': 'Why did the chicken cross the road? To get to the '\n",
      "                          'other side!',\n",
      "               'role': 'assistant'},\n",
      "              {'content': 'And another one?', 'role': 'user'},\n",
      "              {'content': 'What do you call a bear with no teeth? A gummy '\n",
      "                          'bear!',\n",
      "               'role': 'assistant'}]}\n",
      "\n",
      "DPO:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['prompt', 'chosen', 'rejected', 'score_chosen', 'score_rejected'],\n",
      "        num_rows: 2\n",
      "    })\n",
      "    eval: Dataset({\n",
      "        features: ['prompt', 'chosen', 'rejected', 'score_chosen', 'score_rejected'],\n",
      "        num_rows: 0\n",
      "    })\n",
      "})\n",
      "{'chosen': 'Why did the chicken cross the road? To get to the other side!',\n",
      " 'prompt': [{'content': 'Hi – tell me a joke.', 'role': 'user'}],\n",
      " 'rejected': \"I don't know any jokes.\",\n",
      " 'score_chosen': 0.7,\n",
      " 'score_rejected': 0.1}\n",
      "\n",
      "Inputs:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['prompt', 'single_turn_prompt', 'single_turn_completion', 'single_turn_metadata'],\n",
      "        num_rows: 4\n",
      "    })\n",
      "    eval: Dataset({\n",
      "        features: ['prompt', 'single_turn_prompt', 'single_turn_completion', 'single_turn_metadata'],\n",
      "        num_rows: 0\n",
      "    })\n",
      "})\n",
      "{'prompt': [{'content': 'Hi – tell me a joke.', 'role': 'user'}],\n",
      " 'single_turn_completion': 'Why did the chicken cross the road?',\n",
      " 'single_turn_metadata': {'topic': 'jokes'},\n",
      " 'single_turn_prompt': 'Tell me a joke.'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from datasets import Dataset, DatasetDict\n",
    "from collabllm.datasets import MultiturnDataset\n",
    "\n",
    "# ------------------------------------------------------ #\n",
    "# 1) Toy corpus: three conversations, four rows total    #\n",
    "# ------------------------------------------------------ #\n",
    "toy_data = [\n",
    "    {  # convo A, turn 2 (higher score)\n",
    "        \"prompt\": [\n",
    "            {\"role\": \"user\", \"content\": \"Hi – tell me a joke.\"},\n",
    "        ],\n",
    "        \"completion\": \"Why did the chicken cross the road? To get to the other side!\",\n",
    "        \"conv_id\": 1,\n",
    "        \"score\": 0.7,\n",
    "        \"single_turn_prompt\": \"Tell me a joke.\",\n",
    "        \"single_turn_completion\": \"Why did the chicken cross the road?\",\n",
    "        \"single_turn_metadata\": {\"topic\": \"jokes\"},\n",
    "    },\n",
    "    {  # convo A, turn 2 (lower score)\n",
    "        \"prompt\": [\n",
    "            {\"role\": \"user\", \"content\": \"Hi – tell me a joke.\"},\n",
    "        ],\n",
    "        \"completion\": \"I don't know any jokes.\",\n",
    "        \"conv_id\": 1,\n",
    "        \"score\": 0.1,\n",
    "        \"single_turn_prompt\": \"Tell me a joke.\",\n",
    "        \"single_turn_completion\": \"I don't know any jokes.\",\n",
    "        \"single_turn_metadata\": {\"topic\": \"jokes\"},\n",
    "    },\n",
    "    {  # convo A, turn 4 (higher score)\n",
    "        \"prompt\": [\n",
    "            {\"role\": \"user\", \"content\": \"Hi – tell me a joke.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Why did the chicken cross the road? To get to the other side!\"}, # the same as turn 2 (higher score)\n",
    "            {\"role\": \"user\", \"content\": \"And another one?\"},\n",
    "        ],\n",
    "        \"completion\": \"What do you call a bear with no teeth? A gummy bear!\",\n",
    "        \"conv_id\": 1,\n",
    "        \"score\": 0.8,\n",
    "        \"single_turn_prompt\": \"Tell me a joke.\",\n",
    "        \"single_turn_completion\": \"I don't know any jokes.\",\n",
    "        \"single_turn_metadata\": {\"topic\": \"jokes\"},\n",
    "    },\n",
    "    {  # convo A, turn 4 (lower score)\n",
    "        \"prompt\": [\n",
    "            {\"role\": \"user\", \"content\": \"Hi – tell me a joke.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Why did the chicken cross the road? To get to the other side!\"},\n",
    "            {\"role\": \"user\", \"content\": \"And another one?\"},\n",
    "        ],\n",
    "        \"completion\": \"I don't know any jokes.\",\n",
    "        \"conv_id\": 1,\n",
    "        \"score\": 0.1,\n",
    "        \"single_turn_prompt\": \"Tell me a joke.\",\n",
    "        \"single_turn_completion\": \"I don't know any jokes.\",\n",
    "        \"single_turn_metadata\": {\"topic\": \"jokes\"},\n",
    "    },\n",
    "    {  # convo B, turn 4\n",
    "        \"prompt\": [\n",
    "            {\"role\": \"user\", \"content\": \"Sum 2+2\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"4\"},\n",
    "            {\"role\": \"user\", \"content\": \"And 3+3?\"},\n",
    "        ],\n",
    "        \"completion\": \"6\",\n",
    "        \"conv_id\": 2,\n",
    "        \"score\": 0.9,\n",
    "        \"single_turn_prompt\": \"What is 3+3?\",\n",
    "        \"single_turn_completion\": \"6\",\n",
    "        \"single_turn_metadata\": {\"topic\": \"math\"},\n",
    "    },\n",
    "    {  # convo C, turn 2\n",
    "        \"prompt\": [{\"role\": \"user\", \"content\": \"Quote Shakespeare\"}],\n",
    "        \"completion\": \"To be, or not to be.\",\n",
    "        \"conv_id\": 3,\n",
    "        \"score\": 0.5,\n",
    "        \"single_turn_prompt\": \"Quote Shakespeare\",\n",
    "        \"single_turn_completion\": \"To be, or not to be.\",\n",
    "        \"single_turn_metadata\": {\"topic\": \"literature\"},\n",
    "    },\n",
    "]\n",
    "\n",
    "# Add system prompt (by default)\n",
    "# ds = MultiturnDataset(toy_data, seed=42)\n",
    "\n",
    "ds = MultiturnDataset(toy_data, seed=42, add_system_prompt=False)\n",
    "\n",
    "# ------------------------------------------------------ #\n",
    "# 2) SFT                                                 #\n",
    "# ------------------------------------------------------ #\n",
    "sft = ds.to_sft_dataset()\n",
    "print(\"\\nSFT:\")\n",
    "print(sft)\n",
    "pprint(sft[\"train\"][0])\n",
    "\n",
    "# You can filter out conversations where the `lower_bound_metric` at the last turn is below `lower_bound`.\n",
    "sft = ds.to_sft_dataset(lower_bound_metric=\"score\", lower_bound=0.6)\n",
    "print(\"\\nSFT (lower bound=0.6):\")\n",
    "print(sft)\n",
    "pprint(sft[\"train\"][0])\n",
    "\n",
    "# ------------------------------------------------------ #\n",
    "# 3) DPO (gap filter 0.2)                                #\n",
    "# ------------------------------------------------------ #\n",
    "# You can convert to DPO dataset, which will filter out conversations where scores between chosen and rejected completions are lower than `minimum_gap`\n",
    "dpo = ds.to_dpo_dataset(minimum_gap=0.2)\n",
    "print(\"\\nDPO:\")\n",
    "print(dpo)\n",
    "if len(dpo[\"train\"]) > 0:\n",
    "    pprint(dpo[\"train\"][0])\n",
    "\n",
    "# ------------------------------------------------------ #\n",
    "# 4) Inputs                                              #\n",
    "# ------------------------------------------------------ #\n",
    "inputs = ds.to_inputs_dataset()\n",
    "print(\"\\nInputs:\")\n",
    "print(inputs)\n",
    "pprint(inputs[\"train\"][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1.2: Create a multiturn dataset from a list of data entries (nested dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-14 16:51:32,838 [INFO] collabllm.datasets.multiturn: Converted 2 dialogues (filter: None ≥ 0.0); retention ratio: 1.00\n",
      "2025-06-14 16:51:32,852 [INFO] collabllm.datasets.multiturn: Converted 1 pairs (minimum_gap=0.3, ratio=0.25)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SFT from nested data ===\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['messages'],\n",
      "        num_rows: 2\n",
      "    })\n",
      "    eval: Dataset({\n",
      "        features: ['messages'],\n",
      "        num_rows: 0\n",
      "    })\n",
      "})\n",
      "{'messages': [{'content': 'Another one?', 'role': 'user'},\n",
      "              {'content': 'Why did the chicken cross the road? To get to the '\n",
      "                          'other side!',\n",
      "               'role': 'assistant'},\n",
      "              {'content': 'Yes, another.', 'role': 'user'},\n",
      "              {'content': 'What do you call a bear with no teeth? A gummy '\n",
      "                          'bear!',\n",
      "               'role': 'assistant'}]}\n",
      "\n",
      "=== DPO from nested data ===\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['prompt', 'chosen', 'rejected', 'score_chosen', 'score_rejected'],\n",
      "        num_rows: 1\n",
      "    })\n",
      "    eval: Dataset({\n",
      "        features: ['prompt', 'chosen', 'rejected', 'score_chosen', 'score_rejected'],\n",
      "        num_rows: 0\n",
      "    })\n",
      "})\n",
      "{'chosen': 'Why did the chicken cross the road? To get to the other side!',\n",
      " 'prompt': [{'content': 'Hi, tell me a joke.', 'role': 'user'}],\n",
      " 'rejected': 'I don’t know any jokes.',\n",
      " 'score_chosen': 0.7,\n",
      " 'score_rejected': 0.2}\n",
      "\n",
      "=== Inputs from nested data ===\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['prompt', 'single_turn_prompt', 'single_turn_completion', 'single_turn_metadata'],\n",
      "        num_rows: 3\n",
      "    })\n",
      "    eval: Dataset({\n",
      "        features: ['prompt', 'single_turn_prompt', 'single_turn_completion', 'single_turn_metadata'],\n",
      "        num_rows: 0\n",
      "    })\n",
      "})\n",
      "{'prompt': [{'content': 'Hi, tell me a joke.', 'role': 'user'}],\n",
      " 'single_turn_completion': 'Why did the chicken cross the road?',\n",
      " 'single_turn_metadata': {'category': 'humor'},\n",
      " 'single_turn_prompt': 'Tell me a joke.'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "from datasets import DatasetDict\n",
    "from collabllm.datasets import MultiturnDataset\n",
    "\n",
    "# ------------------------------------------------------ #\n",
    "# 1) Example with nested input format                    #\n",
    "# ------------------------------------------------------ #\n",
    "nested_data = [\n",
    "    {\n",
    "        \"single_turn_prompt\": \"Tell me a joke.\",\n",
    "        \"single_turn_completion\": \"Why did the chicken cross the road?\",\n",
    "        \"single_turn_metadata\": {\"category\": \"humor\"},\n",
    "        \"turns\": [\n",
    "            {\n",
    "                \"prompt\": [{\"role\": \"user\", \"content\": \"Hi, tell me a joke.\"}],\n",
    "                \"responses\": [\n",
    "                    {\"completion\": \"Why did the chicken cross the road? To get to the other side!\", \"score\": 0.7},\n",
    "                    {\"completion\": \"I don’t know any jokes.\", \"score\": 0.2},\n",
    "                ],\n",
    "            },\n",
    "            {\n",
    "                \"prompt\": [\n",
    "                    {\"role\": \"user\", \"content\": \"Another one?\"},\n",
    "                    {\"role\": \"assistant\", \"content\": \"Why did the chicken cross the road? To get to the other side!\"},\n",
    "                    {\"role\": \"user\", \"content\": \"Yes, another.\"},\n",
    "                ],\n",
    "                \"responses\": [\n",
    "                    {\"completion\": \"What do you call a bear with no teeth? A gummy bear!\", \"score\": 0.8},\n",
    "                ],\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"single_turn_prompt\": \"Sum 2+2.\",\n",
    "        \"single_turn_completion\": \"2+2=4\",\n",
    "        \"single_turn_metadata\": {\"category\": \"math\"},\n",
    "        \"turns\": [\n",
    "            {\n",
    "                \"prompt\": [{\"role\": \"user\", \"content\": \"Sum 2+2\"}],\n",
    "                \"responses\": [\n",
    "                    {\"completion\": \"4\", \"score\": 0.9},\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "ds_nested = MultiturnDataset(nested_data, seed=123, add_system_prompt=False)\n",
    "\n",
    "# Add system prompt (by default)\n",
    "# ds_nested = MultiturnDataset(nested_data, seed=123, add_system_prompt=True)\n",
    "\n",
    "print(\"=== SFT from nested data ===\")\n",
    "sft_ds: DatasetDict = ds_nested.to_sft_dataset()\n",
    "print(sft_ds)\n",
    "pprint(sft_ds[\"train\"][0])  # one example from train split\n",
    "\n",
    "print(\"\\n=== DPO from nested data ===\")\n",
    "dpo_ds: DatasetDict = ds_nested.to_dpo_dataset(minimum_gap=0.3)\n",
    "print(dpo_ds)\n",
    "if len(dpo_ds[\"train\"]) > 0:\n",
    "    pprint(dpo_ds[\"train\"][0])\n",
    "\n",
    "print(\"\\n=== Inputs from nested data ===\")\n",
    "inputs_ds: DatasetDict = ds_nested.to_inputs_dataset()\n",
    "print(inputs_ds)\n",
    "pprint(inputs_ds[\"train\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2.1: Create a multiturn dataset from huggingface dataset repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-14 16:51:35,956 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=11 (turn_id=9) due to rewards.accuracy=0.000 < 0.500\n",
      "2025-06-14 16:51:35,957 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=15 (turn_id=5) due to rewards.accuracy=0.000 < 0.500\n",
      "2025-06-14 16:51:35,957 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=17 (turn_id=13) due to rewards.accuracy=0.000 < 0.500\n",
      "2025-06-14 16:51:35,957 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=18 (turn_id=5) due to rewards.accuracy=0.000 < 0.500\n",
      "2025-06-14 16:51:35,958 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=19 (turn_id=7) due to rewards.accuracy=0.000 < 0.500\n",
      "2025-06-14 16:51:35,958 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=29 (turn_id=13) due to rewards.accuracy=0.000 < 0.500\n",
      "2025-06-14 16:51:35,958 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=32 (turn_id=5) due to rewards.accuracy=0.000 < 0.500\n",
      "2025-06-14 16:51:35,959 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=39 (turn_id=1) due to rewards.accuracy=0.000 < 0.500\n",
      "2025-06-14 16:51:35,959 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=43 (turn_id=13) due to rewards.accuracy=0.333 < 0.500\n",
      "2025-06-14 16:51:35,959 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=44 (turn_id=13) due to rewards.accuracy=0.000 < 0.500\n",
      "2025-06-14 16:51:35,960 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=48 (turn_id=11) due to rewards.accuracy=0.000 < 0.500\n",
      "2025-06-14 16:51:35,960 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=52 (turn_id=9) due to rewards.accuracy=0.000 < 0.500\n",
      "2025-06-14 16:51:35,960 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=55 (turn_id=7) due to rewards.accuracy=0.000 < 0.500\n",
      "2025-06-14 16:51:35,961 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=61 (turn_id=7) due to rewards.accuracy=0.000 < 0.500\n",
      "2025-06-14 16:51:35,961 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=62 (turn_id=7) due to rewards.accuracy=0.000 < 0.500\n",
      "2025-06-14 16:51:35,962 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=64 (turn_id=3) due to rewards.accuracy=0.000 < 0.500\n",
      "2025-06-14 16:51:35,962 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=69 (turn_id=13) due to rewards.accuracy=0.000 < 0.500\n",
      "2025-06-14 16:51:35,962 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=70 (turn_id=13) due to rewards.accuracy=0.000 < 0.500\n",
      "2025-06-14 16:51:35,963 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=74 (turn_id=3) due to rewards.accuracy=0.000 < 0.500\n",
      "2025-06-14 16:51:35,963 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=83 (turn_id=7) due to rewards.accuracy=0.000 < 0.500\n",
      "2025-06-14 16:51:35,963 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=85 (turn_id=13) due to rewards.accuracy=0.000 < 0.500\n",
      "2025-06-14 16:51:35,964 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=91 (turn_id=9) due to rewards.accuracy=0.000 < 0.500\n",
      "2025-06-14 16:51:35,964 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=97 (turn_id=7) due to rewards.accuracy=0.000 < 0.500\n",
      "2025-06-14 16:51:35,964 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=99 (turn_id=13) due to rewards.accuracy=0.000 < 0.500\n",
      "2025-06-14 16:51:35,964 [INFO] collabllm.datasets.multiturn: Converted 76 dialogues (filter: rewards.accuracy ≥ 0.5); retention ratio: 0.76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SFT ===\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['messages'],\n",
      "        num_rows: 69\n",
      "    })\n",
      "    eval: Dataset({\n",
      "        features: ['messages'],\n",
      "        num_rows: 7\n",
      "    })\n",
      "})\n",
      "{'messages': [{'content': 'The assistant is designed to be helpful, proactive, and highly interactive.\\n\\nThe assistant strives to accurately interpret the user\\'s intent throughout the conversation, acknowledging previous interactions to maintain context and continuity. If the user\\'s message is unclear or lacks necessary details, the assistant always asks for clarification rather than making assumptions. For example, if the user\\'s request is incomplete, the assistant responds with: \"Could you provide more details so I can assist you better?\"\\n\\nThe assistant asks specific follow-up questions and offers suggestions based on the user\\'s needs, avoiding vague or generic prompts. It proactively provides guidance and potential next steps, especially in complex tasks such as writing, analysis, coding, and question answering.\\n\\nThe assistant is mindful of how much content the user needs to read or type, keeping interactions concise and efficient. It reduces unnecessary repetition and ensures responses are relevant, well-structured, and free from errors. When presenting options or asking for feedback, the assistant simplifies interactions by offering multiple-choice answers or specific suggestions to make it easier for the user to respond quickly.\\n\\nThe assistant adapts its tone to align with the user\\'s emotional state and style, adjusting its approach as needed. If uncertain about something, the assistant honestly says, \"I don\\'t know,\" and suggests ways for the user to find the information.\\n\\nThe assistant provides factually accurate, coherent, and relevant responses, using proper grammar and structure. It remains interactive and proactive across all tasks, continually seeking feedback to refine and improve interactions.', 'role': 'system'}, {'content': \"Hey, I'm trying to solve a problem involving two infinite geometric series. The first series has a first term of 12 and a second term of 4. The second series has the same first term of 12, but its second term is 4+n, and the sum is four times that of the first series. Any ideas on how to find the value of n?\", 'role': 'user'}, {'content': 'To solve this problem, we need to analyze the given geometric series. \\n\\n### First Series\\nThe first term \\\\( a_1 \\\\) of the first series is 12, and the second term is 4. In a geometric series, the second term is given by \\\\( a_1 \\\\cdot r_1 \\\\), where \\\\( r_1 \\\\) is the common ratio. Therefore, we have:\\n\\\\[\\n12 \\\\cdot r_1 = 4\\n\\\\]\\nSolving for \\\\( r_1 \\\\), we get:\\n\\\\[\\nr_1 = \\\\frac{4}{12} = \\\\frac{1}{3}\\n\\\\]\\n\\nThe sum \\\\( S_1 \\\\) of the first infinite geometric series is given by:\\n\\\\[\\nS_1 = \\\\frac{a_1}{1 - r_1} = \\\\frac{12}{1 - \\\\frac{1}{3}} = \\\\frac{12}{\\\\frac{2}{3}} = 18\\n\\\\]\\n\\n### Second Series\\nThe second series has the same first term, 12, and a second term of \\\\( 4 + n \\\\). This second term is equal to \\\\( 12 \\\\cdot r_2 \\\\), where \\\\( r_2 \\\\) is the common ratio for the second series:\\n\\\\[\\n12 \\\\cdot r_2 = 4 + n\\n\\\\]\\nSolving for \\\\( r_2 \\\\), we get:\\n\\\\[\\nr_2 = \\\\frac{4 + n}{12}\\n\\\\]\\n\\nThe sum \\\\( S_2 \\\\) of the second infinite geometric series is given by:\\n\\\\[\\nS_2 = \\\\frac{a_1}{1 - r_2} = \\\\frac{12}{1 - \\\\frac{4+n}{12}} = \\\\frac{12}{\\\\frac{12 - 4 - n}{12}} = \\\\frac{12 \\\\cdot 12}{8 - n}\\n\\\\]\\n\\n### Relationship Between Series\\nWe are told that the sum of the second series is four times the sum of the first series:\\n\\\\[\\nS_2 = 4 \\\\cdot S_1\\n\\\\]\\n\\\\[\\n\\\\frac{144}{8 - n} = 4 \\\\times 18\\n\\\\]\\n\\\\[\\n\\\\frac{144}{8 - n} = 72\\n\\\\]\\n\\nNow, solve for \\\\( n \\\\):\\n\\\\[\\n144 = 72 \\\\times (8 - n)\\n\\\\]\\n\\\\[\\n144 = 576 - 72n\\n\\\\]\\n\\\\[\\n72n = 576 - 144\\n\\\\]\\n\\\\[\\n72n = 432\\n\\\\]\\n\\\\[\\nn = \\\\frac{432}{72} = 6\\n\\\\]\\n\\nThus, the value of \\\\( n \\\\) is \\\\( \\\\boxed{6} \\\\).', 'role': 'assistant'}]}\n"
     ]
    }
   ],
   "source": [
    "from collabllm.datasets import MultiturnDataset\n",
    "\n",
    "ds = MultiturnDataset('collabllm/collabllm-multiturn-math-hard', add_system_prompt=True)\n",
    "\n",
    "print(\"=== SFT ===\")\n",
    "sft_ds: DatasetDict = ds.to_sft_dataset(eval_ratio=0.1, lower_bound_metric=\"rewards.accuracy\", lower_bound=0.5)\n",
    "print(sft_ds)\n",
    "print(sft_ds[\"train\"][0])  # one example from train split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When specify DPO dataset, set `minimum_gap` to filter out pairs where the score difference is below `minimum_gap`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-14 16:51:35,995 [INFO] collabllm.datasets.multiturn: Converted 250 pairs (minimum_gap=0.1, ratio=0.23)\n",
      "2025-06-14 16:51:36,013 [INFO] collabllm.datasets.multiturn: Converted 188 pairs (minimum_gap=0.2, ratio=0.18)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DPO (minimum gap = 0.1) ===\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['prompt', 'chosen', 'rejected', 'score_chosen', 'score_rejected'],\n",
      "        num_rows: 225\n",
      "    })\n",
      "    eval: Dataset({\n",
      "        features: ['prompt', 'chosen', 'rejected', 'score_chosen', 'score_rejected'],\n",
      "        num_rows: 25\n",
      "    })\n",
      "})\n",
      "\n",
      "=== DPO (minimum gap = 0.2) ===\n",
      "dict_keys(['train', 'eval'])\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== DPO (minimum gap = 0.1) ===\")\n",
    "dpo_ds: DatasetDict = ds.to_dpo_dataset(minimum_gap=0.1, eval_ratio=0.1)\n",
    "print(dpo_ds)\n",
    "\n",
    "print(\"\\n=== DPO (minimum gap = 0.2) ===\")\n",
    "dpo_ds: DatasetDict = ds.to_dpo_dataset(minimum_gap=0.2, eval_ratio=0.1)\n",
    "print(dpo_ds.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Inputs ===\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['prompt', 'single_turn_prompt', 'single_turn_completion', 'single_turn_metadata'],\n",
      "        num_rows: 320\n",
      "    })\n",
      "    eval: Dataset({\n",
      "        features: ['prompt', 'single_turn_prompt', 'single_turn_completion', 'single_turn_metadata'],\n",
      "        num_rows: 35\n",
      "    })\n",
      "})\n",
      "dict_keys(['prompt', 'single_turn_prompt', 'single_turn_completion', 'single_turn_metadata'])\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Inputs ===\")\n",
    "inputs_ds: DatasetDict = ds.to_inputs_dataset(eval_ratio=0.1)\n",
    "print(inputs_ds)\n",
    "print(inputs_ds[\"train\"][0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2.2: Create a multiturn dataset from a local directory\n",
    "\n",
    "You can load the dataset from a local directory which is saved by `ds.save_to_disk` where ds is a HuggingFace Dataset object."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "collabllm-beta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
